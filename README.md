# Dialogue-Summarization-with-FLAN-T5-and-LoRA-Fine-Tuning
This repository contains an advanced dialogue summarization system using FLAN-T5, optimized with LoRA (Low-Rank Adaptation) for enhanced performance. It features both extractive and abstractive summarization approaches, leveraging fine-tuning techniques to improve the quality of summaries generated from customer support conversations.

## Project Overview

This project focuses on advanced dialogue summarization techniques to enhance the summarization of customer support conversations.

## Models and Techniques

- **Extractive Summarization**: Implemented using word frequency-based extraction to identify and summarize key sentences from dialogues.

- **Abstractive Summarization**: Implemented using Google's FLAN-T5 model, fine-tuned with the PEFT (Parameter Efficient Fine-Tuning) approach, specifically using the LoRA (Low-Rank Adaptation) strategy.
